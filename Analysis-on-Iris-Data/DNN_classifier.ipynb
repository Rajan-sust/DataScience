{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNWeArfXwQQmaWhkUv+I+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajan-sust/ML/blob/master/Analysis-on-Iris-Data/DNN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFR9UwuGgEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEBIPbHhGs0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I99Z1tVXM_w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# Add the first (input) layer (1000 nodes) with input shape 4 element vector (1D).\n",
        "model.add(Dense(1000, input_shape=(4,), activation='relu'))\n",
        "# Add the second (hidden) layer (500 nodes).\n",
        "model.add(Dense(500, activation='relu'))\n",
        "# Add the third (hidden) layer (300 nodes).\n",
        "model.add(Dense(300,activation='relu'))\n",
        "# Add dropout\n",
        "model.add(Dropout(0.2))\n",
        "# Add the (output) layer of 3 nodes, and set the activation function to a Softmax.\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "# Use the Categorical Cross Entropy loss function for a Multi-Class Classifier.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm_aVeRKNEFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "93865f6f-adf3-41aa-f619-010c8decc2d3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 1000)              5000      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 300)               150300    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 903       \n",
            "=================================================================\n",
            "Total params: 656,703\n",
            "Trainable params: 656,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkBsWfziOemo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_source = 'https://raw.githubusercontent.com/Rajan-sust/ML/master/Dataset/iris/train.csv'\n",
        "data = pd.read_csv(train_data_source, names=['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wgG5PzdRcei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = data.iloc[:, 0:4].values, data['species']\n",
        "y_train = y_train.apply(lambda x: {'Iris-virginica' : 0, 'Iris-versicolor' : 1, 'Iris-setosa' : 2}[x])\n",
        "y_train = to_categorical(y_train.values, num_classes = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc6j0he3RqzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c9f3bee-0353-4a67-cf78-572f706d8722"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100, validation_split=0.1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 108 samples, validate on 12 samples\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 0s 449us/sample - loss: 0.0657 - accuracy: 0.9907 - val_loss: 0.1245 - val_accuracy: 0.9167\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 438us/sample - loss: 0.1030 - accuracy: 0.9537 - val_loss: 0.1267 - val_accuracy: 0.9167\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 407us/sample - loss: 0.1090 - accuracy: 0.9537 - val_loss: 0.0822 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 448us/sample - loss: 0.0756 - accuracy: 0.9722 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 471us/sample - loss: 0.0629 - accuracy: 0.9815 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 509us/sample - loss: 0.0665 - accuracy: 0.9722 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 431us/sample - loss: 0.0778 - accuracy: 0.9537 - val_loss: 0.1063 - val_accuracy: 0.9167\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0939 - accuracy: 0.9630 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 508us/sample - loss: 0.0717 - accuracy: 0.9722 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 494us/sample - loss: 0.0686 - accuracy: 0.9722 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 466us/sample - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 474us/sample - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 506us/sample - loss: 0.0608 - accuracy: 0.9815 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 481us/sample - loss: 0.0935 - accuracy: 0.9630 - val_loss: 0.0933 - val_accuracy: 0.9167\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 454us/sample - loss: 0.0979 - accuracy: 0.9630 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 466us/sample - loss: 0.0563 - accuracy: 0.9907 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 475us/sample - loss: 0.0590 - accuracy: 0.9907 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 462us/sample - loss: 0.0734 - accuracy: 0.9722 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 436us/sample - loss: 0.0828 - accuracy: 0.9815 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 401us/sample - loss: 0.1080 - accuracy: 0.9444 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 489us/sample - loss: 0.0748 - accuracy: 0.9815 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 444us/sample - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0739 - accuracy: 0.9815 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 473us/sample - loss: 0.0646 - accuracy: 0.9815 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 530us/sample - loss: 0.0587 - accuracy: 0.9815 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 586us/sample - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 475us/sample - loss: 0.0660 - accuracy: 0.9815 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 457us/sample - loss: 0.0528 - accuracy: 0.9907 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 655us/sample - loss: 0.0738 - accuracy: 0.9630 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 481us/sample - loss: 0.0559 - accuracy: 0.9815 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 450us/sample - loss: 0.0505 - accuracy: 0.9907 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 406us/sample - loss: 0.0545 - accuracy: 0.9907 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 451us/sample - loss: 0.0623 - accuracy: 0.9815 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 485us/sample - loss: 0.0603 - accuracy: 0.9907 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 497us/sample - loss: 0.0724 - accuracy: 0.9722 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 426us/sample - loss: 0.0672 - accuracy: 0.9815 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 422us/sample - loss: 0.0519 - accuracy: 0.9815 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 432us/sample - loss: 0.0777 - accuracy: 0.9630 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 437us/sample - loss: 0.0547 - accuracy: 0.9907 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 445us/sample - loss: 0.0460 - accuracy: 0.9815 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 424us/sample - loss: 0.0657 - accuracy: 0.9722 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 495us/sample - loss: 0.0653 - accuracy: 0.9722 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 486us/sample - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 472us/sample - loss: 0.0577 - accuracy: 0.9815 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 3ms/sample - loss: 0.0440 - accuracy: 0.9907 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 489us/sample - loss: 0.0468 - accuracy: 0.9907 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 471us/sample - loss: 0.0471 - accuracy: 0.9815 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 465us/sample - loss: 0.0516 - accuracy: 0.9907 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 474us/sample - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 486us/sample - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 510us/sample - loss: 0.0494 - accuracy: 0.9722 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 488us/sample - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 498us/sample - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 509us/sample - loss: 0.0497 - accuracy: 0.9907 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 472us/sample - loss: 0.0470 - accuracy: 0.9907 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 443us/sample - loss: 0.0496 - accuracy: 0.9815 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 457us/sample - loss: 0.0507 - accuracy: 0.9907 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 476us/sample - loss: 0.0512 - accuracy: 0.9907 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 472us/sample - loss: 0.0413 - accuracy: 0.9907 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 480us/sample - loss: 0.0978 - accuracy: 0.9630 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 459us/sample - loss: 0.0480 - accuracy: 0.9815 - val_loss: 0.1547 - val_accuracy: 0.9167\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 435us/sample - loss: 0.0963 - accuracy: 0.9537 - val_loss: 0.1460 - val_accuracy: 0.9167\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 460us/sample - loss: 0.1171 - accuracy: 0.9630 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 461us/sample - loss: 0.0804 - accuracy: 0.9630 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 478us/sample - loss: 0.0915 - accuracy: 0.9722 - val_loss: 0.1445 - val_accuracy: 0.9167\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0856 - accuracy: 0.9630 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 466us/sample - loss: 0.0453 - accuracy: 0.9907 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 456us/sample - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 500us/sample - loss: 0.0498 - accuracy: 0.9907 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 476us/sample - loss: 0.0648 - accuracy: 0.9722 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 463us/sample - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 482us/sample - loss: 0.0354 - accuracy: 0.9907 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 453us/sample - loss: 0.0441 - accuracy: 0.9815 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 480us/sample - loss: 0.0744 - accuracy: 0.9630 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 430us/sample - loss: 0.0367 - accuracy: 0.9907 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 440us/sample - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 413us/sample - loss: 0.0650 - accuracy: 0.9815 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 434us/sample - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 425us/sample - loss: 0.0502 - accuracy: 0.9722 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 451us/sample - loss: 0.0900 - accuracy: 0.9630 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 432us/sample - loss: 0.1836 - accuracy: 0.9352 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 438us/sample - loss: 0.0697 - accuracy: 0.9815 - val_loss: 0.0997 - val_accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0691 - accuracy: 0.9722 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0485 - accuracy: 0.9815 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 468us/sample - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.1231 - val_accuracy: 0.9167\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 477us/sample - loss: 0.0736 - accuracy: 0.9722 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 469us/sample - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 478us/sample - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 482us/sample - loss: 0.0608 - accuracy: 0.9722 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 500us/sample - loss: 0.0465 - accuracy: 0.9907 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 444us/sample - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 552us/sample - loss: 0.0513 - accuracy: 0.9815 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 479us/sample - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 452us/sample - loss: 0.0448 - accuracy: 0.9907 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 440us/sample - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 467us/sample - loss: 0.0376 - accuracy: 0.9907 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 484us/sample - loss: 0.0400 - accuracy: 0.9907 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 505us/sample - loss: 0.0354 - accuracy: 0.9907 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 441us/sample - loss: 0.0365 - accuracy: 0.9907 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 445us/sample - loss: 0.0382 - accuracy: 0.9907 - val_loss: 0.0235 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1752cf7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tJ842G-S9KL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73450de9-5cab-4ae1-f137-78c3bad60b35"
      },
      "source": [
        "model.predict([[5.2,3.4,1.4,0.2]])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0783819e-16, 1.4391367e-07, 9.9999988e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmFq_yOW73s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WLmaYkhW8Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym5df_vaW8UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}